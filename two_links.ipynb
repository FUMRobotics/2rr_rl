{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005ff5a8-e668-47cc-8c5e-971730f7e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 11 2021 20:59:39\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Box\n",
    "\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "from pybullet_utils import bullet_client\n",
    "\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fdcf7d7-e226-44f4-bad1-a8626fce744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RENDER_HEIGHT = 360\n",
    "RENDER_WIDTH = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a8317a-8f19-4a71-b04a-6ddbeec729f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Goal:\n",
    "    def __init__(self, client, base):\n",
    "        # f_name = os.path.join(os.path.dirname(__file__), 'goal.urdf')\n",
    "        p.loadURDF(fileName=\"goal.urdf\",\n",
    "                   basePosition=[base[0], base[1], 0],\n",
    "                   physicsClientId=client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beba0c2d-7047-4d10-9175-61770e5f5dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot:\n",
    "    def __init__(self, client, goal_position):\n",
    "        self.client = client\n",
    "        self.robot = p.loadURDF(fileName=\"2links.urdf\",\n",
    "                              basePosition=[-0.3,-0.3,0],\n",
    "                              physicsClientId=client)\n",
    "    \n",
    "        self.arm = 2\n",
    "        self.endEffector = 3\n",
    "        \n",
    "        self.joints_indecies=[1, 2]\n",
    "        \n",
    "        self.joint_1_velocity=0\n",
    "        self.joint_2_velocity=0\n",
    "        self.np_random, _ = gym.utils.seeding.np_random()\n",
    "        self.goal_position = goal_position\n",
    "        random_move_steps = 10\n",
    "        pj1 = self.np_random.uniform(-90, 90)\n",
    "        pj2 = self.np_random.uniform(-180, 180)\n",
    "        \n",
    "        # print(p.getJointInfo(self.robot, jointIndex=1, physicsClientId=self.client))\n",
    "        # print(p.getJointInfo(self.robot, jointIndex=2, physicsClientId=self.client))\n",
    "        # print(p.getJointInfo(self.robot, jointIndex=0, physicsClientId=self.client))\n",
    "        p.resetJointState(self.robot, 1,\n",
    "                            targetValue=pj1,\n",
    "                            physicsClientId=self.client)\n",
    "\n",
    "        p.resetJointState(self.robot, 2,\n",
    "                            targetValue=pj2,\n",
    "                            physicsClientId=self.client)\n",
    "\n",
    "#         for i in range(0, random_move_steps):\n",
    "            \n",
    "\n",
    "#             p.setJointMotorControl2(self.robot, 1,\n",
    "#                                 p.POSITION_CONTROL,\n",
    "#                                 targetPosition=pj1,\n",
    "#                                 physicsClientId=self.client)\n",
    "        \n",
    "#             p.setJointMotorControl2(self.robot, 2,\n",
    "#                                 p.POSITION_CONTROL,\n",
    "#                                 targetPosition=pj2,\n",
    "#                                 physicsClientId=self.client)\n",
    "\n",
    "#             p.stepSimulation(physicsClientId=self.client)\n",
    "            \n",
    "#         for i in range(0, random_move_steps):\n",
    "#             p.setJointMotorControl2(self.robot, 1,\n",
    "#                                 p.VELOCITY_CONTROL,\n",
    "#                                 targetVelocity=0,\n",
    "#                                 physicsClientId=self.client)\n",
    "        \n",
    "#             p.setJointMotorControl2(self.robot, 2,\n",
    "#                                 p.VELOCITY_CONTROL,\n",
    "#                                 targetVelocity=0,\n",
    "#                                 physicsClientId=self.client)\n",
    "\n",
    "\n",
    "#             p.stepSimulation(physicsClientId=self.client)\n",
    "        \n",
    "        \n",
    "    def apply_action(self, action):\n",
    "        j1, j2 = action\n",
    "        # self.joint_1_velocity=j1\n",
    "        # self.joint_2_velocity=j2\n",
    "        p.setJointMotorControl2(\n",
    "                bodyIndex=self.robot,\n",
    "                jointIndex=1,\n",
    "                controlMode=p.TORQUE_CONTROL,\n",
    "                force=j1) \n",
    "        p.setJointMotorControl2(\n",
    "                bodyIndex=self.robot,\n",
    "                jointIndex=2,\n",
    "                controlMode=p.TORQUE_CONTROL,\n",
    "                force=j2) \n",
    "#         p.setJointMotorControl2(self.robot, 1,\n",
    "#                                 p.VELOCITY_CONTROL,\n",
    "#                                 targetVelocity=j1,\n",
    "#                                 physicsClientId=self.client)\n",
    "        \n",
    "#         p.setJointMotorControl2(self.robot, 2,\n",
    "#                                 p.VELOCITY_CONTROL,\n",
    "#                                 targetVelocity=j2,\n",
    "#                                 physicsClientId=self.client)\n",
    "        \n",
    "        # p.setJointMotorControlArray(self.robot, self.joints_indecies,\n",
    "        #                             controlMode=p.VELOCITY_CONTROL,\n",
    "        #                             targetVelocities=[j1, j2],\n",
    "        #                             physicsClientId=self.client)\n",
    "        \n",
    "    def get_observation(self):\n",
    "        \n",
    "        joint1_state = p.getJointState(self.robot, 1, physicsClientId=self.client)\n",
    "        joint2_state = p.getJointState(self.robot, 2, physicsClientId=self.client)\n",
    "        \n",
    "        pj1, vj1, fj1, tj1 = joint1_state\n",
    "        pj2, vj2, fj2, tj2 = joint2_state\n",
    "        pj1s = np.sin(pj1)\n",
    "        pj1c = np.cos(pj1)\n",
    "        pj2s = np.sin(pj2)\n",
    "        pj2c = np.cos(pj2)\n",
    "        return np.array([pj1s, pj1c, pj2s, pj2c, vj1, vj2, tj1 / 100000.0, tj2 / 100000.0, self.goal_position[0], self.goal_position[1]])\n",
    "        \n",
    "    \n",
    "    def get_endeffector_postion(self):\n",
    "        arm_link_state = p.getLinkState(self.robot, self.endEffector)\n",
    "        x, y, z = arm_link_state[0]\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def get_ids(self):\n",
    "        return self.robot, self.client\n",
    "    \n",
    "    def get_base_position(self):\n",
    "        return p.getBasePositionAndOrientation(self.robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58748118-9d74-4389-a237-8f455a8042a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plane:\n",
    "    def __init__(self, client):\n",
    "        # f_name = os.path.join(os.path.dirname(__file__), 'goal.urdf')\n",
    "        p.loadURDF(fileName=\"plane.urdf\",\n",
    "                   basePosition=[0, 0, 0],\n",
    "                   physicsClientId=client)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f29e6955-f017-47be-b116-22df29c7d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLinkRobotEnv(Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, open_mode=p.DIRECT):\n",
    "        self.max_x, self.max_y, self.max_z, self.max_vel = 0.75,0.75,0.55, 0.7\n",
    "        self.action_space = Box(low=np.array([-1, -1]),high=np.array([1, 1]), dtype=np.float64)\n",
    "        self.observation_space = Box(low=-float('inf'), high=float('inf'), shape=(10, ), dtype=np.float64)\n",
    "        \n",
    "        self.isRender = open_mode == p.GUI\n",
    "        \n",
    "        self.client = -1\n",
    "        \n",
    "        self.robot = None\n",
    "        self.goal = None\n",
    "        self.done = False\n",
    "        self.prev_dist_to_goal = None\n",
    "        self.prev_vj1 = 0\n",
    "        self.prev_vj2 = 0\n",
    "        self.rendered_img = None\n",
    "        self.render_rot_matrix = None\n",
    "        self.epsilon = 0.01\n",
    "        self.num_envs=10\n",
    "        self.np_random, _ = gym.utils.seeding.np_random()\n",
    "        self.closed = False\n",
    "        self.max_number_of_tries = 5000\n",
    "        self.cost_rate = 0.0000000001\n",
    "        self._cam_dist = 3\n",
    "        self._cam_yaw = 0\n",
    "        self._cam_pitch = -30\n",
    "        self.time_step = 1./200 #1.0/200\n",
    "        self._state = self.reset()\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        self.number_of_tries += 1\n",
    "        # print(action)\n",
    "        \n",
    "        self.robot.apply_action(action * 100000)\n",
    "        p.stepSimulation()\n",
    "        \n",
    "        observation = self.robot.get_observation()\n",
    "        self._state = observation\n",
    "        \n",
    "        reward = self.claculate_reward(action)\n",
    "        \n",
    "        return observation, reward, self.done, {}\n",
    "    \n",
    "    def claculate_reward(self, action):\n",
    "        \n",
    "        joint1_state = p.getJointState(self.robot.robot, 1, physicsClientId=self.client)\n",
    "        joint2_state = p.getJointState(self.robot.robot, 2, physicsClientId=self.client)\n",
    "        \n",
    "        pj1, vj1, fj1, tj1 = joint1_state\n",
    "        pj2, vj2, fj2, tj2 = joint2_state\n",
    "        \n",
    "        x, y = self.robot.get_endeffector_postion()\n",
    "        \n",
    "        # dist_to_goal = abs(x - self.goal[0]) + abs(y - self.goal[1])\n",
    "        dist_to_goal = math.sqrt((x - self.goal[0]) ** 2 + (y - self.goal[1]) ** 2)\n",
    "        \n",
    "        reward = 0\n",
    "        \n",
    "        if abs(dist_to_goal) <= (self.epsilon):\n",
    "            #check V is zero\n",
    "            # print(abs(vj1), abs(vj2))\n",
    "            reward = 10000 - (vj1**2 + vj2 **2) / 10\n",
    "            self.done = True\n",
    "            # if abs(vj1) <0.4 and abs(vj2) < 0.4:\n",
    "            #     reward = 800\n",
    "            #     self.done = True\n",
    "            # elif abs(vj1) <3.4 and abs(vj2) < 3.4:\n",
    "            #     reward = 400\n",
    "            #     self.done = True\n",
    "            # elif abs(vj1) <10.4 and abs(vj2) < 10.4:\n",
    "            #     reward = 200\n",
    "            #     self.done = True\n",
    "        else:\n",
    "            reward -= dist_to_goal / 100.\n",
    "        \n",
    "        if self.number_of_tries >= self.max_number_of_tries:\n",
    "            self.done = True\n",
    "        t1, t2 = action\n",
    "        # cost = (5 * ((tj1) ** 2) + (tj2) ** 2) * (self.cost_rate)  ##\n",
    "        cost = ( 5 * (t1 ** 2) + t2 ** 2 ) / 10000.0\n",
    "        reward -= cost\n",
    "        # print(f\"cost {cost}\")\n",
    "        # print(f\"Reward: {reward}\")\n",
    "        # print(f\"D {dist_to_goal}\")\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        if (self.client<0):\n",
    "            self.ownsPhysicsClient = True\n",
    "\n",
    "\n",
    "            if self.isRender:\n",
    "                  self._p = bullet_client.BulletClient(connection_mode=p.GUI)\n",
    "            else:\n",
    "                    self._p = bullet_client.BulletClient()\n",
    "\n",
    "            self.client = self._p._client\n",
    "            self._p.configureDebugVisualizer(p.COV_ENABLE_GUI,0)\n",
    "        \n",
    "        p.resetSimulation(self.client)\n",
    "        p.setGravity(0, 0, -9.8)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath()) \n",
    "        p.setTimeStep(timeStep=self.time_step, physicsClientId=self.client)\n",
    "        \n",
    "        Plane(self.client)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = (self.np_random.uniform(0.4, 1.25) if self.np_random.randint(20) % 2 == 1 else\n",
    "#              self.np_random.uniform(-0.4, -1.25))\n",
    "        \n",
    "#         y = (self.np_random.uniform(0.4, 1.25) if self.np_random.randint(20) % 2 == 1 else\n",
    "#              self.np_random.uniform(-0.4, -1.25))\n",
    "        \n",
    "        x = (self.np_random.uniform(0.3, 1.16) if self.np_random.randint(20) % 2 == 1 else\n",
    "             self.np_random.uniform(-0.3, -1.16))\n",
    "        \n",
    "        y = (self.np_random.uniform(0.3, 1.16) if self.np_random.randint(20) % 2 == 1 else\n",
    "             self.np_random.uniform(-0.3, -1.16))\n",
    "        self.goal = (x, y)\n",
    "        self.done = False\n",
    "        \n",
    "        self.robot = Robot(self.client, self.goal)\n",
    "        \n",
    "        Goal(self.client, self.goal)\n",
    "        \n",
    "        observation = self.robot.get_observation()\n",
    "        \n",
    "        self.number_of_tries = 0\n",
    "        \n",
    "        return observation\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        base_pos, _ = self.robot.get_base_position()\n",
    "        view_matrix = self._p.computeViewMatrixFromYawPitchRoll(\n",
    "            cameraTargetPosition=base_pos,\n",
    "            distance=self._cam_dist,\n",
    "            yaw=self._cam_yaw,\n",
    "            pitch=self._cam_pitch,\n",
    "            roll=0,\n",
    "            upAxisIndex=2)\n",
    "        proj_matrix = self._p.computeProjectionMatrixFOV(fov=60,\n",
    "                                                                       aspect=float(RENDER_WIDTH) / RENDER_HEIGHT,\n",
    "                                                                       nearVal=0.1,\n",
    "                                                                       farVal=100.0)\n",
    "        (_, _, px, _, _) = self._p.getCameraImage(\n",
    "            width=RENDER_WIDTH,\n",
    "            height=RENDER_HEIGHT,\n",
    "            renderer=self._p.ER_BULLET_HARDWARE_OPENGL,\n",
    "            viewMatrix=view_matrix,\n",
    "            projectionMatrix=proj_matrix)\n",
    "        rgb_array = np.array(px)\n",
    "        rgb_array = rgb_array[:, :, :3]\n",
    "        return rgb_array\n",
    "    \n",
    "    def close(self):\n",
    "        self.closed = True\n",
    "        p.disconnect(self.client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826e5762-5b27-4358-ac07-55d6a2643288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env(TwoLinkRobotEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c63468d-cffa-48e4-a769-fa0b0c86dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n"
     ]
    }
   ],
   "source": [
    "def make_env(id):\n",
    "    def _init():\n",
    "        if id == 1:\n",
    "            env = TwoLinkRobotEnv(p.GUI)\n",
    "        else :\n",
    "            env = TwoLinkRobotEnv()\n",
    "        return Monitor(env, \"env_logs/2rr_logs_\" + str(id) + \".csv\")\n",
    "    return _init\n",
    "\n",
    "number_of_cpu = 18\n",
    "env = SubprocVecEnv([make_env(i) for i in range(number_of_cpu)])\n",
    "# env = DummyVecEnv([lambda:Monitor(TwoLinkRobotEnv(p.GUI))])\n",
    "# episodes = 5\n",
    "# for episode in range(1, episodes+1):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     score = 0 \n",
    "    \n",
    "#     while not done:\n",
    "#         action = env.action_space.sample()\n",
    "#         n_state, reward, done, info = env.step(action)\n",
    "#         score+=reward\n",
    "#     print('Episode:{} Score:{}'.format(episode, score))\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f378a4e8-b0e3-4d67-967b-819d46397f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(\"2rr_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084d88f6-96c4-4300-babd-4d44aa7e04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[36, 18], vf=[36, 18])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b87720d7-efbf-427e-8e9c-7dec87f68cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d911ac1-5330-4253-8b97-4247d7885240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71491ef-ff46-41a0-80cb-693e9abefea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "pybullet build time: Oct 11 2021 20:59:39\n",
      "2021-11-05 00:01:25.270058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/rosim/.local/lib/python3.8/site-packages/cv2/../../lib64:/usr/lib/x86_64-linux-gnu/gazebo-11/plugins:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/home/rosim/.mujoco/mujoco200/bin\n",
      "2021-11-05 00:01:25.270074: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to 2rr_logs/PPO_88\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 9.73e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 6487     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 9.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 3586         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044943765 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 1.6e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 6.69e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.22e+03    |\n",
      "|    ep_rew_mean          | 1.84e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3088        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007583471 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -1.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00522    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.00713     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.29e+03     |\n",
      "|    ep_rew_mean          | 1.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2821         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053207865 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.81        |\n",
      "|    explained_variance   | 6.02e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00565     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 1.86e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.55e+03    |\n",
      "|    ep_rew_mean          | 1.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2745        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005752119 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.00366     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.51e+03    |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2650        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006422427 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | -2.85e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 1.87e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.46e+03    |\n",
      "|    ep_rew_mean          | 1.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2640        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006162281 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 3.37e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00684     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 0.953       |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.41e+03    |\n",
      "|    ep_rew_mean          | 1.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2623        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006515286 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.71       |\n",
      "|    explained_variance   | 2.41e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.934       |\n",
      "|    value_loss           | 4.02e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.3e+03     |\n",
      "|    ep_rew_mean          | 1.86e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2623        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007468567 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.67       |\n",
      "|    explained_variance   | -5.84e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 6.75e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.37e+03     |\n",
      "|    ep_rew_mean          | 1.67e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2612         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 141          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072574806 |\n",
      "|    clip_fraction        | 0.0757       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.63        |\n",
      "|    explained_variance   | 9.33e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0119       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 4.3e+04      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.41e+03    |\n",
      "|    ep_rew_mean          | 1.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2595        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006444695 |\n",
      "|    clip_fraction        | 0.066       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 2.85e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 2.29e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.38e+03     |\n",
      "|    ep_rew_mean          | 1.61e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2585         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082550645 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00172     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    std                  | 0.863        |\n",
      "|    value_loss           | 0.00504      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.47e+03    |\n",
      "|    ep_rew_mean          | 1.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2574        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007924663 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 3.74e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00887    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 1.88e+04    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)\n",
    "model.learn(total_timesteps=30000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9a748-052d-4daf-bfcf-d164794d50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"two_links_model_3m_reward_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a107f-2582-4b7b-b1e0-5c493c136d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_policy(model, env, n_eval_episodes=50, render=False)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6eb330-428f-4978-b800-b70cedb1536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_env = TwoLinkRobotEnv(p.GUI)\n",
    "# model = PPO.load(\"two_links_model_3m_new_reward_2\")\n",
    "# evaluate_policy(model, new_env, n_eval_episodes=20, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7503937f-907b-47b5-9538-ef8e3de4e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab17566-3b88-4dc4-8a5d-4de38d364598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc094bf1-4344-4709-98e1-c93baaca1007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
